group_by(book, chapter) %>%
summarize(positivewords = n()) %>%
left_join(wordcounts, by = c("book", "chapter")) %>%
mutate(positive_ratio = positivewords/words) %>%
filter(chapter != 0) %>%
top_n(1) %>%
ungroup()
## Load frequently used packages for blog posts
library('knitcitations') # for citations
library('BiocStyle') # for CRANpkg() Biocpkg() Githubpkg()
library('devtools') # for session_info()
## Load knitcitations with a clean bibliography
cleanbib()
cite_options(hyperlink = 'to.doc', citation_format = 'text', style = 'html')
bib <- c(
'rtweet' = citation('rtweet'),
'rmarkdown' = citation('rmarkdown'),
'NLP' = citation('NLP'),
'tm' = citation('tm'),
'RColorBrewer' = citation('RColorBrewer'),
'wordcloud' = citation('wordcloud'),
'topicmodels' = citation('topicmodels'),
'SnowballC' = citation('SnowballC'),
'config' = citation('config'),
'dplyr' = citation('dplyr'),
'tidytext' = citation('tidytext'),
'tidyr' = citation('tidyr'),
'ggplot2' = citation('ggplot2'),
'lubridate' = citation('lubridate'),
'readr' = citation('readr'),
'skimr' = citation('skimr'),
'blogdown' = citation('blogdown')[2],
'devtools' = citation('devtools'),
'knitcitations' = citation('knitcitations')
)
?datatable()
#summary(tweet_df)
skim_table <- skim(tweets_df) %>%
DT::datatable(
caption="",
filter="top",
width = 600,
rownames=FALSE
)
widget <- skim_table
widgetfile <- 'skim_table.html'
htmlwidgets::saveWidget(widget = widget
, selfcontained = TRUE
, file = widgetfile)
cat(paste0('<iframe src= "', widgetfile, '" width="100%" height="400" style="border: none;"></iframe>'))
#summary(tweet_df)
skim_table <- skim(tweets_df) %>%
DT::datatable(
caption="",
filter="top",
rownames=FALSE,
options=list(
dom='Bfrtip',
pageLength=10,
autoWidth=TRUE
)
)
nrow(tweets_df) %>%knitr::kable()
nrow(tweets_df) %>% print()
library(leaflet)
tweet_map <- leaflet(tweets_df) %>%
addTiles() %>%
addCircleMarkers(lng = ~lng
, lat = ~lat)
tweet_map
blogdown:::serve_site()
# Knitr options: https://yihui.org/knitr/options/
library(lubridate)
knitr::opts_chunk$set(collapse = TRUE
, eval = TRUE
, echo = TRUE
, message = FALSE
, warning = FALSE
, include = TRUE)
library(rtweet)
library(rmarkdown)
library(NLP)
library(tm)
library(RColorBrewer)
library(wordcloud)
library(topicmodels)
library(SnowballC)
library(config)
library(dplyr)
library(tidytext)
library(tidyr)
library(ggplot2)
library(lubridate)
library(readr)
library(skimr)
tweets_df <- readRDS("tweets_df.Rds")
tweets_df %>% head() %>% knitr::kable()
library(leaflet)
tweet_map <- leaflet(tweets_df) %>%
addTiles() %>%
addCircleMarkers(lng = ~lng
, lat = ~lat)
widget <- tweet_map
tweet_map
blogdown:::serve_site()
blogdown:::serve_site()
build_dir(force = TRUE)
blogdown::build_dir(force = TRUE)
blogdown:::serve_site()
blogdown::stop_server()
blogdown:::serve_site()
blogdown:::serve_site()
# Knitr options: https://yihui.org/knitr/options/
library(lubridate)
knitr::opts_chunk$set(collapse = TRUE
, eval = TRUE
, echo = TRUE
, message = FALSE
, warning = FALSE
, include = TRUE)
library(rtweet)
library(rmarkdown)
library(NLP)
library(tm)
library(RColorBrewer)
library(wordcloud)
library(topicmodels)
library(SnowballC)
library(config)
library(dplyr)
library(tidytext)
library(tidyr)
library(ggplot2)
library(lubridate)
library(readr)
library(skimr)
tweets_df <- readRDS("tweets_df.Rds")
tweets_df %>% head()
tweets_df %>% select(
# About the tweet
text
, lang
, hashtags
, symbols
, favorite_count
, retweet_count
, lat
, lng
# About the user
, name
, screen_name
, followers_count
, friends_count
, location
, description
, listed_count
, statuses_count
, created_at
, account_created_at
) %>%
head(2)
nrow(tweets_df) %>% print()
tweets_df %>%
slice_max(favorite_count, n = 1) %>% # can also use arrange()
select(screen_name
, text
, favorite_count
, created_at) %>% knitr::kable()
top_tweeters <- tweets_df %>%
group_by(screen_name) %>%
summarize(num_tweets = n()) %>%
arrange(-num_tweets) %>% # can also use slice_max()
ungroup() %>%
head(5)
ggplot(top_tweeters) +
geom_histogram(aes(x = screen_name, y = num_tweets, fill = screen_name), stat = 'identity') +
theme_minimal() +
scale_fill_viridis_d(option = "viridis") +
labs(title = "What users are tweeting the most?") +
theme(legend.position = "none") +
xlab("") +
ylab("Number of Tweets")
tweets_df %>%
group_by(lang) %>%
summarize(num_tweets = n()) %>%
arrange(-num_tweets) %>% # can also use slice_max()
head(5)
# ggplot(tweets_df) +
#   geom_bar(aes(x = lang, fill = lang))
users_by_source <- tweets_df %>%
group_by(source) %>%
summarize(num_users = n_distinct(user_id)) %>%
arrange(-num_users) %>% # can also use slice_max()
ungroup() %>%
head(10)
ggplot(users_by_source) +
geom_histogram(aes(x = reorder(source, num_users), y = num_users, fill = source), stat = 'identity') +
scale_fill_viridis_d(option = "viridis") +
coord_flip() +
theme_gray() +
theme(legend.position = "none") +
#theme(legend.title = element_blank()) +
labs(title = "Top 10 Twitter Platforms People are Using") +
xlab("") +
ylab("Number of Users") +
scale_y_continuous(breaks = seq(0, 400, by=50), limits = c(0, 400), expand = c(0, 0)) + # use expand() to remove empty space between axis and bars
geom_hline(yintercept = seq(0, 400, by = 25), color = 'white')
tweets_per_day <- tweets_df %>%
group_by(tweet_date) %>%
summarize(num_tweets = n()) %>%
arrange(-num_tweets) %>% # can also use slice_max()
ungroup()
# Using ggplot + plotly
library(plotly)
plt1 <- ggplot(tweets_per_day) +
geom_line(aes(x = tweet_date, y = num_tweets)) +
scale_fill_viridis_d(option = "viridis") +
theme_gray() +
theme(legend.position = "none") +
labs(title = "Daily Tweets") +
xlab("") +
ylab("Number of Tweets")
pltly1 <- plotly::ggplotly(plt1)
widget <- pltly1
widgetfile <- 'pltly1.html'
htmlwidgets::saveWidget(widget = widget
, selfcontained = TRUE
, file = widgetfile)
cat(paste0('<iframe src= "', widgetfile, '" width="100%" height="400" style="border: none;"></iframe>'))
# Using dygraph
# convert series to an xts object
tweets_ts <- xts::xts(tweets_per_day$num_tweets, order.by = tweets_per_day$tweet_date)
# Create the dygraph
library(dygraphs)
dygraph1 <- dygraph(tweets_ts, main = "Daily Tweets for 'Philadelphia'") %>%
dySeries("V1", label = "Tweet Count")
widget <- dygraph1
widgetfile <- 'dygraph1.html'
htmlwidgets::saveWidget(widget = widget
, selfcontained = TRUE
, file = widgetfile)
cat(paste0('<iframe src= "', widgetfile, '" width="100%" height="400" style="border: none;"></iframe>'))
library(leaflet)
tweet_map <- leaflet(tweets_df) %>%
addTiles() %>%
addCircleMarkers(lng = ~lng
, lat = ~lat)
widget <- tweet_map
widgetfile <- 'tweet_map.html'
htmlwidgets::saveWidget(widget = widget
, selfcontained = TRUE
, file = widgetfile)
cat(paste0('<iframe src= "', widgetfile, '" width="100%" height="400" style="border: none;"></iframe>'))
#install.packages("textdata")
library(tidytext)
get_sentiments("afinn") %>% head() %>% knitr::kable(caption = 'AFINN')
get_sentiments("bing") %>% head() %>% knitr::kable(caption = 'Bing et. al.')
get_sentiments("nrc") %>% head() %>% knitr::kable(caption = 'NRC')
library(stringr)
library(janeaustenr)
tidy_books <- austen_books() %>%
group_by(book) %>%
mutate(
linenumber = row_number(),
chapter = cumsum(str_detect(text,
regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup() %>%
unnest_tokens(word, text)
tidy_books %>% head() %>% knitr::kable()
tweets_book <- cbind('Philadelphia', tweets_df$text) %>% data.frame()
colnames(tweets_book) <- c('book', 'text')
# Reformat the date - running above insists on converting the `tweet_date` value to its integer form.
tweets_book$chapter <- tweets_df$tweet_date
tidy_books <- tweets_book %>%
group_by(book) %>%
mutate(
linenumber = row_number()
) %>%
ungroup() %>%
unnest_tokens(word, text)
tidy_books %>% head() %>% knitr::kable()
nrc_joy <- get_sentiments("nrc") %>%
filter(sentiment == "joy")
head(nrc_joy) %>% knitr::kable()
tidy_books %>%
filter(book == "Philadelphia") %>%
inner_join(nrc_joy) %>%
count(word, sort = TRUE) %>%
head(10) %>% knitr::kable()
philly_sentiment <- tidy_books %>%
inner_join(get_sentiments("bing")) %>%
#count(book, index = linenumber %/% 80, sentiment) %>% # 80-line tweet chunks
count(book, index = chapter, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
ggplot(philly_sentiment) +
geom_col(aes(index, sentiment, fill = sentiment)) +
#facet_wrap(~book, ncol = 1, scales = "free_x") # apply if we'relooking across multiple books +
labs(title = "Sentiment of 'Philadelphia' Tweets") +
scale_fill_gradient2(low='red', mid='orange', high='navy') +
#scale_fill_viridis_c(option = "viridis") +
theme(legend.position = "none") +
xlab("") +
ylab("Sentiment")
philly_tweets <- tidy_books %>%
filter(book == "Philadelphia")
## afinn
afinn <- philly_tweets %>%
inner_join(get_sentiments("afinn")) %>%
#group_by(index = linenumber %/% 80) %>% # Can use 80-line chunks
group_by(index = chapter) %>% # or other type of index value, like date
summarise(sentiment = sum(value)) %>%
mutate(method = "AFINN")
## rbinding bing and nrc
bing_and_nrc <- bind_rows(
philly_tweets %>%
inner_join(get_sentiments("bing")) %>%
mutate(method = "Bing et al."),
philly_tweets %>%
inner_join(get_sentiments("nrc") %>%
filter(sentiment %in% c("positive",
"negative"))
) %>%
mutate(method = "NRC")) %>%
#count(method, index = linenumber %/% 80, sentiment) %>% # Can use 80-line chunks
count(method, index = chapter, sentiment) %>% # or other type of index value, like date
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
bind_rows(afinn,
bing_and_nrc) %>%
ggplot(aes(index, sentiment, fill = method)) +
geom_col(show.legend = FALSE) +
facet_wrap(~method, ncol = 1, scales = "free_y") +
labs(title = "Sentiment of 'Philadelphia' Tweets - Lexicon Comparison") +
scale_fill_viridis_d(option = "viridis") +
theme(legend.position = "none") +
xlab("") +
ylab("Sentiment")
get_sentiments("nrc") %>%
filter(sentiment %in% c("positive", "negative")) %>%
count(sentiment) %>% knitr::kable()
get_sentiments("bing") %>%
count(sentiment) %>% knitr::kable()
bing_word_counts <- tidy_books %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
bing_word_counts %>% head(10) %>% knitr::kable()
bing_word_counts %>%
group_by(sentiment) %>%
top_n(10) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(n, word, fill = sentiment)) +
geom_col(show.legend = FALSE) +
scale_fill_viridis_d(option = "viridis") +
facet_wrap(~sentiment, scales = "free_y") +
labs(x = "Contribution to sentiment",
y = NULL)
custom_stop_words <- bind_rows(tibble(word = c('philadelphia', 'philly', 't.co', 'https', 'amp'),
lexicon = c("custom")),
stop_words)
custom_stop_words %>% head() %>% knitr::kable()
library(wordcloud)
tidy_books %>%
anti_join(custom_stop_words) %>%
count(word) %>%
with(wordcloud(word, n, max.words = 100, col = brewer.pal(8, "Dark2")))
library(reshape2)
tidy_books %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("orange", "navy"),
max.words = 100)
bingpositive <- get_sentiments("bing") %>%
filter(sentiment == "positive")
wordcounts <- tidy_books %>%
group_by(book, chapter) %>%
summarize(words = n())
tidy_books %>%
semi_join(bingpositive) %>%
group_by(book, chapter) %>%
summarize(positivewords = n()) %>%
left_join(wordcounts, by = c("book", "chapter")) %>%
mutate(positive_ratio = positivewords/words) %>%
filter(chapter != 0) %>%
top_n(1) %>%
ungroup()
## Load frequently used packages for blog posts
library('knitcitations') # for citations
library('BiocStyle') # for CRANpkg() Biocpkg() Githubpkg()
library('devtools') # for session_info()
## Load knitcitations with a clean bibliography
cleanbib()
cite_options(hyperlink = 'to.doc', citation_format = 'text', style = 'html')
bib <- c(
'knitr' = citation('knitr'),
'rtweet' = citation('rtweet'),
'rmarkdown' = citation('rmarkdown'),
'NLP' = citation('NLP'),
'tm' = citation('tm'),
'RColorBrewer' = citation('RColorBrewer'),
'wordcloud' = citation('wordcloud'),
'topicmodels' = citation('topicmodels'),
'SnowballC' = citation('SnowballC'),
'config' = citation('config'),
'dplyr' = citation('dplyr'),
'tidytext' = citation('tidytext'),
'tidyr' = citation('tidyr'),
'ggplot2' = citation('ggplot2'),
'lubridate' = citation('lubridate'),
'readr' = citation('readr'),
'skimr' = citation('skimr'),
'blogdown' = citation('blogdown')[2],
'devtools' = citation('devtools'),
'knitcitations' = citation('knitcitations')
)
blogdown:::serve_site()
# Knitr options: https://yihui.org/knitr/options/
library(dplyr)
library(ggplot2)
library(lubridate)
knitr::opts_chunk$set(collapse = TRUE
, eval = TRUE
, echo = TRUE
, message = FALSE
, warning = FALSE
, include = TRUE)
splashdown_colors <- c(
`ebony` = "#1E2225",
`blue_grotto` = "#05263B",
`charcoal` = "#43758A",
`light_sea_green` = "#36B4AF",
`pewter` = "#D3DADA",
`carafe` = "#55423A",
`goldenrod` = "#F1B416",
`burnt_sienna` = "#E56A19",
`crimson` = "#900000")
splashdown_cols <- function(...) {
cols <- c(...)
if (is.null(cols))
return (splashdown_colors)
splashdown_colors[cols]
}
library(scales)
library(dplyr)
par(mfrow=c(1,2))
splashdown_cols() %>% show_col()
splashdown_cols("light_sea_green", "burnt_sienna") %>% show_col()
ggplot(mtcars, aes(hp, mpg)) +
geom_point(color = splashdown_cols("goldenrod"),
size = 4, alpha = .8)
splashdown_palettes <- list(
`primary`  = splashdown_cols("ebony", "blue_grotto", "charcoal", "light_sea_green", "pewter"),
`secondary`  = splashdown_cols("carafe", "goldenrod", "burnt_sienna", "crimson"),
`all`   = splashdown_cols("ebony", "blue_grotto", "charcoal", "light_sea_green", "pewter", "carafe", "goldenrod", "burnt_sienna", "crimson")
)
splashdown_pal <- function(palette = "main", reverse = FALSE, ...) {
pal <- splashdown_palettes[[palette]]
if (reverse) pal <- rev(pal)
colorRampPalette(pal, ...)
}
par(mfrow=c(1,2))
splashdown_pal("primary")(12) %>% show_col()
splashdown_pal("secondary")(4) %>% show_col()
scale_color_rjfranssen <- function(palette = "main",
discrete = TRUE,
reverse = FALSE,
...) {
pal <- splashdown_pal(palette = palette, reverse = reverse)
if (discrete) {
discrete_scale("colour", paste0("splashdown_", palette), palette = pal, ...)
} else {
scale_color_gradientn(colours = pal(256), ...)
}
}
scale_fill_rjfranssen <- function(palette = "main", discrete = TRUE, reverse = FALSE, ...) {
pal <- splashdown_pal(palette = palette, reverse = reverse)
if (discrete) {
discrete_scale("fill", paste0("splashdown_", palette), palette = pal, ...)
} else {
scale_fill_gradientn(colours = pal(256), ...)
}
}
ggplot(iris, aes(Sepal.Width, Sepal.Length, color = Sepal.Length)) +
geom_point(size = 4, alpha = .6) +
scale_color_rjfranssen(discrete = FALSE, palette = "primary")
ggplot(iris, aes(Sepal.Width, Sepal.Length, color = Species)) +
geom_point(size = 4) +
scale_color_rjfranssen("secondary")
ggplot(mpg, aes(manufacturer, fill = manufacturer)) +
geom_bar() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
scale_fill_rjfranssen(palette = "all", guide = "none")
## Load frequently used packages for blog posts
library('knitcitations') # for citations
library('BiocStyle') # for CRANpkg() Biocpkg() Githubpkg()
library('devtools') # for session_info()
## Load knitcitations with a clean bibliography
cleanbib()
cite_options(hyperlink = 'to.doc', citation_format = 'text', style = 'html')
bib <- c(
'lubridate' = citation('lubridate'),
'dplyr' = citation('dplyr'),
'ggplot2' = citation('ggplot2'),
'BiocStyle' = citation('BiocStyle'),
'blogdown' = citation('blogdown')[2],
'devtools' = citation('devtools'),
'knitcitations' = citation('knitcitations')
)
