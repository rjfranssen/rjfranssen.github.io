'knitcitations' = citation('knitcitations')
)
# Calculate reading time
bytes <- file.size("index.Rmarkdown")
words <- bytes/10
minutes <- words/100
`r today()` | _`r round(minutes)` min_
`r today()` | _`r round(minutes)` min_
blogdown:::preview_site()
blogdown:::preview_site()
# Knitr options: https://yihui.org/knitr/options/
library(lubridate)
knitr::opts_chunk$set(collapse = TRUE
, eval = TRUE
, echo = TRUE
, message = FALSE
, warning = FALSE
, include = TRUE)
## Load frequently used packages for blog posts
library('knitcitations') # for citations
library('BiocStyle') # for CRANpkg() Biocpkg() Githubpkg()
library('devtools') # for session_info()
## Load knitcitations with a clean bibliography
cleanbib()
cite_options(hyperlink = 'to.doc', citation_format = 'text', style = 'html')
bib <- c(
'rgdal' = citation('rgdal'),
'leaflet' = citation('leaflet'),
'dplyr' = citation('dplyr'),
'data.table' = citation('data.table'),
'htmlwidgets' = citation('htmlwidgets'),
'BiocStyle' = citation('BiocStyle'),
'blogdown' = citation('blogdown')[2],
'devtools' = citation('devtools'),
'knitcitations' = citation('knitcitations')
)
# Calculate reading time
bytes <- file.size("index.Rmarkdown")
words <- bytes/10
minutes <- words/100
csv_url <- params$dataloc
download.file(csv_url, destfile = "mpg.csv", method = "curl")
df <- data.table::fread("mpg.csv")
df2 <- df[df$manufacturer == params$manufacturer, ]
plt <- ggplot(df2) +
geom_bar( aes(x = as.factor(cyl), fill = as.factor(cyl)), stat = 'count') +
scale_fill_viridis_d(option = "viridis") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
theme(legend.position = "none")
#ggplotly(plt)
plt
df2 <- df[df$manufacturer == params$plotvar, ]
plt <- ggplot(df2) +
geom_point(aes(x = displ, y = hwy, color = as.factor(year), label = model), size = 5) +
scale_color_viridis_d(option = "viridis") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
theme(legend.position = "none")
#ggplotly(plt)
plt
df2 <- df[df$manufacturer == params$manufacturer, ]
plt <- ggplot(df2) +
geom_point(aes(x = displ, y = hwy, color = as.factor(year), label = model), size = 5) +
scale_color_viridis_d(option = "viridis") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
theme(legend.position = "none")
#ggplotly(plt)
plt
plt <- ggplot(df) +
geom_bar( aes(manufacturer, fill = manufacturer), stat = 'count') +
scale_fill_viridis_d(option = "viridis") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
theme(legend.position = "none")
#ggplotly(plt)
plt
plt <- ggplot(df) +
geom_point(aes(x = cty, y = hwy, color = manufacturer), alpha = 0.6) +
scale_fill_viridis_d(option = "viridis") +
facet_wrap(~manufacturer) +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
theme(legend.position = "none")
#ggplotly(plt)
plt
csv_url <- "https://raw.githubusercontent.com/tidyverse/ggplot2/master/data-raw/mpg.csv"
download.file(csv_url, destfile = "mpg.csv", method = "curl")
df <- data.table::fread("mpg.csv")
blogdown:::preview_site()
blogdown:::serve_site()
blogdown:::preview_site()
install.packages("blogdown")
install.packages("blogdown")
install.packages("blogdown")
install.packages("blogdown")
install.packages("blogdown")
blogdown:::serve_site()
blogdown:::new_post_addin()
ggplotly(mtcats)
library(ggplot2)
library(dplyr)
library(plotly)
ggplotly(mtcats)
ggplotly(mtcars)
ggplotly(ggplot(mtcats))
ggplotly(ggplot(mtcars))
plot(mtcars)
plot(mtcars) %>% ggplotly()
leaflet() + addTiles()
library(leaflet)
leaflet() + addTiles()
mtcars %>% ggplot()
str(mtcars)
mtcars %>% ggplot(aes(mpg, cyl))
mtcars %>% ggplot(aes(mpg, cyl)) + geom_point()
ggplotly(plt)
plt <- mtcars %>% ggplot(aes(mpg, cyl)) + geom_point()
ggplotly(plt)
plt <- mtcars %>% ggplot(aes(mpg, cyl)) + geom_point()
ggplotly(plt)
blogdown:::new_post_addin()
library(ggplot2)
library(dplyr)
library(plotly)
plt <- mtcars %>% ggplot(aes(mpg, cyl)) + geom_point()
ggplotly(plt)
blogdown:::serve_site()
# Knitr options: https://yihui.org/knitr/options/
library(lubridate)
library(dplyr)
library(plotly)
knitr::opts_chunk$set(collapse = TRUE
, eval = TRUE
, echo = TRUE
, message = FALSE
, warning = FALSE
, include = TRUE)
# Function to render this rmd file as an html doc; run this in R console
render_report = function(manufacturer = params$manufacturer, date = params$date) {
rmarkdown::render(
input = "parameterized-reporting-example.Rmd",
output_format = "html_document",
params = list(
manufacturer = manufacturer,
date = date
),
output_file = paste0('reports/', manufacturer, "_mpg_report_", date, ".html")
)
}
# Knitr options: https://yihui.org/knitr/options/
library(lubridate)
library(dplyr)
library(plotly)
knitr::opts_chunk$set(collapse = TRUE
, eval = TRUE
, echo = TRUE
, message = FALSE
, warning = FALSE
, include = TRUE)
csv_url <- params$dataloc
download.file(csv_url, destfile = "mpg.csv", method = "curl")
df <- data.table::fread("mpg.csv")
df2 <- df[df$manufacturer == params$manufacturer, ]
plt <- ggplot(df2) +
geom_bar( aes(x = as.factor(cyl), fill = as.factor(cyl)), stat = 'count') +
scale_fill_viridis_d(option = "viridis") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
theme(legend.position = "none")
ggplotly(plt)
#plt
df2 <- df[df$manufacturer == params$manufacturer, ]
plt <- ggplot(df2) +
geom_point(aes(x = displ, y = hwy, color = as.factor(year), label = model), size = 5) +
scale_color_viridis_d(option = "viridis") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
theme(legend.position = "none")
ggplotly(plt)
#plt
plt <- ggplot(df) +
geom_bar( aes(manufacturer, fill = manufacturer), stat = 'count') +
scale_fill_viridis_d(option = "viridis") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
theme(legend.position = "none")
ggplotly(plt)
#plt
# Function to render this rmd file as an html doc; run this in R console
render_report = function(manufacturer = params$manufacturer, date = params$date) {
rmarkdown::render(
input = "parameterized-reporting-example.Rmd",
output_format = "html_document",
params = list(
manufacturer = manufacturer,
date = date
),
output_file = paste0('reports/', manufacturer, "_mpg_report_", date, ".html")
)
}
# Test one-off report with default params
render_report()
# Now loop through and create one report for each manufacturer
# (note: need to pull down the file and create `df` before running)
for (i in unique(df$manufacturer)){
render_report(manufacturer = i)
print(paste0('finished knitting ', i))
}
# Function to render this rmd file as an html doc; run this in R console
render_report = function(manufacturer = params$manufacturer, date = params$date) {
rmarkdown::render(
input = "parameterized-reporting-example.Rmd",
output_format = "html_document",
params = list(
manufacturer = manufacturer,
date = date
),
output_file = paste0('reports/', manufacturer, "_mpg_report_", date, ".html")
)
}
# Now loop through and create one report for each manufacturer
# (note: need to pull down the file and create `df` before running)
for (i in unique(df$manufacturer)){
render_report(manufacturer = i)
print(paste0('finished knitting ', i))
}
blogdown:::serve_site()
blogdown:::serve_site()
# Knitr options: https://yihui.org/knitr/options/
library(lubridate)
knitr::opts_chunk$set(collapse = TRUE
, eval = TRUE
, echo = TRUE
, message = FALSE
, warning = FALSE
, include = TRUE)
library(rtweet)
library(rmarkdown)
library(NLP)
library(tm)
library(RColorBrewer)
library(wordcloud)
library(topicmodels)
library(SnowballC)
library(config)
library(dplyr)
library(tidytext)
library(tidyr)
library(ggplot2)
library(lubridate)
library(readr)
library(skimr)
config <- config::get(file = 'config.yml')
## authenticate via web browser
token <- create_token(
app = config$app,
consumer_key = config$apikey,
consumer_secret = config$apikeysecret,
access_token = config$accesstoken,
access_secret = config$accesstokensecret)
# Search tweets using rtweet search function
tweets_df <- rtweet::search_tweets(
q = 'philadelphia philly'
, n = 2000
, include_rts = FALSE
, type = 'recent'
#, geocode = "37.78, -122.40, 1mi"
#, retryonratelimit = TRUE
#, parse = FALSE
#, lang = 'en'
# ... see Twitter's REST API for more search parameters
)
## Create lat/lng variables using all available tweet and profile geo-location data
tweets_df <- rtweet::lat_lng(tweets_df)
## Also going to create some friendlier date variables;`created_at` is a `POSIXct` type that requires a bit of tender loving care. WIll still keep the `created_at` value, which works great with `dygraphs` and just fine with `ggplot2`, but I want to be able to group by date variables.
tweets_df$tweet_datetime <- tweets_df$created_at
tweets_df$tweet_date <- tweets_df$created_at %>% as.POSIXlt() %>% as.Date() %>% ymd()
tweets_df$tweet_year <- tweets_df$created_at %>% as.POSIXlt() %>% as.Date() %>% year()
tweets_df$tweet_month <- tweets_df$created_at %>% as.POSIXlt() %>% as.Date() %>% month()
tweets_df$tweet_day <- tweets_df$created_at %>% as.POSIXlt() %>% as.Date() %>% day()
saveRDS(tweets_df, file = "tweets_df.Rds", compress = 'xz')
tweets_df <- readRDS("tweets_df.Rds")
tweets_df %>% head()
tweets_df %>% select(
# About the tweet
text
, lang
, hashtags
, symbols
, favorite_count
, retweet_count
, lat
, lng
# About the user
, name
, screen_name
, followers_count
, friends_count
, location
, description
, listed_count
, statuses_count
, created_at
, account_created_at
) %>%
head(2)
nrow(tweets_df) %>% print()
tweets_df %>%
slice_max(favorite_count, n = 1) %>% # can also use arrange()
select(screen_name
, text
, favorite_count
, created_at)
top_tweeters <- tweets_df %>%
group_by(screen_name) %>%
summarize(num_tweets = n()) %>%
arrange(-num_tweets) %>% # can also use slice_max()
ungroup() %>%
head(5)
ggplot(top_tweeters) +
geom_histogram(aes(x = screen_name, y = num_tweets, fill = screen_name), stat = 'identity') +
theme_minimal() +
scale_fill_viridis_d(option = "viridis") +
labs(title = "What users are tweeting the most?") +
theme(legend.position = "none") +
xlab("") +
ylab("Number of Tweets")
tweets_df %>%
group_by(lang) %>%
summarize(num_tweets = n()) %>%
arrange(-num_tweets) %>% # can also use slice_max()
head(5)
# ggplot(tweets_df) +
#   geom_bar(aes(x = lang, fill = lang))
users_by_source <- tweets_df %>%
group_by(source) %>%
summarize(num_users = n_distinct(user_id)) %>%
arrange(-num_users) %>% # can also use slice_max()
ungroup() %>%
head(10)
ggplot(users_by_source) +
geom_histogram(aes(x = reorder(source, num_users), y = num_users, fill = source), stat = 'identity') +
scale_fill_viridis_d(option = "viridis") +
coord_flip() +
theme_gray() +
theme(legend.position = "none") +
#theme(legend.title = element_blank()) +
labs(title = "Top 10 Twitter Platforms People are Using") +
xlab("") +
ylab("Number of Users") +
scale_y_continuous(breaks = seq(0, 450, by=50), limits = c(0, 450), expand = c(0, 0)) + # use expand() to remove empty space between axis and bars
geom_hline(yintercept = seq(0, 450, by = 25), color = 'white')
tweets_per_day <- tweets_df %>%
group_by(tweet_date) %>%
summarize(num_tweets = n()) %>%
arrange(-num_tweets) %>% # can also use slice_max()
ungroup()
# Using ggplot + plotly
library(plotly)
plt1 <- ggplot(tweets_per_day) +
geom_line(aes(x = tweet_date, y = num_tweets)) +
scale_fill_viridis_d(option = "viridis") +
theme_gray() +
theme(legend.position = "none") +
labs(title = "Daily Tweets for 'Philadelphia' (ggplot2 + plotly)") +
xlab("") +
ylab("Number of Tweets")
pltly1 <- plotly::ggplotly(plt1)
widget <- pltly1
widgetfile <- 'pltly1.html'
htmlwidgets::saveWidget(widget = widget
, selfcontained = TRUE
, file = widgetfile)
cat(paste0('<iframe src= "', widgetfile, '" width="100%" height="400" style="border: none;"></iframe>'))
# Using dygraph
# convert series to an xts object
tweets_ts <- xts::xts(tweets_per_day$num_tweets, order.by = tweets_per_day$tweet_date)
# Create the dygraph
library(dygraphs)
dygraph1 <- dygraph(tweets_ts, main = "Daily Tweets for 'Philadelphia' (dygraph)") %>%
dySeries("V1", label = "Tweet Count")
widget <- dygraph1
widgetfile <- 'dygraph1.html'
htmlwidgets::saveWidget(widget = widget
, selfcontained = TRUE
, file = widgetfile)
cat(paste0('<iframe src= "', widgetfile, '" width="100%" height="400" style="border: none;"></iframe>'))
library(leaflet)
tweet_map <- leaflet(tweets_df) %>%
addTiles() %>%
addMarkers(lng = ~lng
, lat = ~lat
, label = ~as.character(text)
, popup = ~as.character(text)
)
widget <- tweet_map
widgetfile <- 'tweet_map.html'
htmlwidgets::saveWidget(widget = widget
, selfcontained = TRUE
, file = widgetfile)
cat(paste0('<iframe src= "', widgetfile, '" width="100%" height="400" style="border: none;"></iframe>'))
#install.packages("textdata")
library(tidytext)
get_sentiments("afinn") %>% head()
get_sentiments("bing") %>% head()
get_sentiments("nrc") %>% head()
library(stringr)
library(janeaustenr)
tidy_books <- austen_books() %>%
group_by(book) %>%
mutate(
linenumber = row_number(),
chapter = cumsum(str_detect(text,
regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup() %>%
unnest_tokens(word, text)
tidy_books %>% head() %>% knitr::kable()
tweets_book <- cbind('Philadelphia', tweets_df$text) %>% data.frame()
colnames(tweets_book) <- c('book', 'text')
# Reformat the date - running above insists on converting the `tweet_date` value to its integer form.
tweets_book$chapter <- tweets_df$tweet_date
tidy_books <- tweets_book %>%
group_by(book) %>%
mutate(
linenumber = row_number()
) %>%
ungroup() %>%
unnest_tokens(word, text)
tidy_books %>% head() %>% knitr::kable()
nrc_joy <- get_sentiments("nrc") %>%
filter(sentiment == "joy")
head(nrc_joy)
tidy_books %>%
filter(book == "Philadelphia") %>%
inner_join(nrc_joy) %>%
count(word, sort = TRUE) %>%
head(10)
philly_sentiment <- tidy_books %>%
inner_join(get_sentiments("bing"), by = c("word" = "word")) %>%
#count(book, index = linenumber %/% 80, sentiment) %>% # 80-line tweet chunks
count(book, index = chapter, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
philly_tweets <- tidy_books %>%
filter(book == "Philadelphia")
## afinn
afinn <- philly_tweets %>%
inner_join(get_sentiments("afinn"), by = c("word" = "word")) %>%
#group_by(index = linenumber %/% 80) %>% # Can use 80-line chunks
group_by(index = chapter) %>% # or other type of index value, like date
summarise(sentiment = sum(value)) %>%
mutate(method = "AFINN") %>%
ungroup()
## rbinding bing and nrc
bing_and_nrc <- bind_rows(
philly_tweets %>%
inner_join(get_sentiments("bing"), by = c("word" = "word")) %>%
mutate(method = "Bing et al."),
philly_tweets %>%
inner_join(get_sentiments("nrc") %>%
filter(sentiment %in% c("positive",
"negative"))
) %>%
mutate(method = "NRC")) %>%
#count(method, index = linenumber %/% 80, sentiment) %>% # Can use 80-line chunks
count(method, index = chapter, sentiment) %>% # or other type of index value, like date
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
bind_rows(afinn,
bing_and_nrc) %>%
ggplot(aes(index, sentiment, fill = method)) +
geom_col(show.legend = FALSE) +
facet_wrap(~method, ncol = 1, scales = "free_y") +
labs(title = "Sentiment of 'Philadelphia' Tweets - Lexicon Comparison") +
scale_fill_viridis_d(option = "viridis") +
theme(legend.position = "none") +
xlab("") +
ylab("Sentiment")
get_sentiments("nrc") %>%
filter(sentiment %in% c("positive", "negative")) %>%
count(sentiment)
get_sentiments("bing") %>%
count(sentiment)
bing_word_counts <- tidy_books %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
bing_word_counts %>% head(10) %>% knitr::kable()
bing_word_counts %>%
group_by(sentiment) %>%
top_n(10) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(n, word, fill = sentiment)) +
geom_col(show.legend = FALSE) +
scale_fill_viridis_d(option = "viridis") +
facet_wrap(~sentiment, scales = "free_y") +
labs(x = "Contribution to sentiment",
y = NULL)
custom_stop_words <- bind_rows(tibble(word = c('philadelphia', 'philly', 't.co', 'https', 'amp'),
lexicon = c("custom")),
stop_words)
custom_stop_words %>% head() %>% knitr::kable()
blogdown:::serve_site()
# Knitr options: https://yihui.org/knitr/options/
library(lubridate)
knitr::opts_chunk$set(collapse = TRUE
, eval = TRUE
, echo = TRUE
, message = FALSE
, warning = FALSE
, include = TRUE)
tidy_books %>%
filter(book == "Philadelphia") %>%
inner_join(nrc_joy) %>%
count(word, sort = TRUE) %>%
head(10)
